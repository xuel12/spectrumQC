{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyteomics\n",
    "from pyteomics import tandem\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "import argparse\n",
    "from pyteomics import mzml, auxiliary\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory is F:\\DS5500_project_1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.chdir('F://DS5500_project_1')\n",
    "    print(\"Current directory is {}\".format(os.getcwd()))\n",
    "except: \n",
    "    print(\"Something wrong with specified directory. Exception- \", sys.exc_info())\n",
    "\n",
    "datadir = os.getcwd()\n",
    "j = 0\n",
    "exist_spectrum_dict = {}\n",
    "speclist = []\n",
    "bin_size = 10\n",
    "for filename in os.listdir(datadir): #iterate through all mzML file\n",
    "    if (re.search('\\\\.mzML$', filename)):\n",
    "        with mzml.read(os.path.join(datadir, filename), 'r') as reader:\n",
    "            for spec in reader:\n",
    "                if (spec['ms level'] == 2):\n",
    "                    tmp_id = [int(spec['id'].split('=')[3])]*len(spec['m/z array'])\n",
    "                    speclist.append(np.column_stack((tmp_id, spec['m/z array'],spec['intensity array'])))\n",
    "            \n",
    "            spectrum_np = np.concatenate(speclist, axis=0)\n",
    "            spectrum_df = pd.DataFrame({'specid':spectrum_np[:,0], 'location':spectrum_np[:,1],'intensity':spectrum_np[:,2]})            \n",
    "            spectrum_df = spectrum_df.assign(interval=spectrum_df['location']//bin_size)\n",
    "            spectrum_df = spectrum_df.groupby(['specid','interval'])['intensity'].sum()\n",
    "            spectrum_df = spectrum_df.reset_index()\n",
    "            convert_dict = {'specid': int, 'interval': int} \n",
    "            exist_spectrum_dict[j] = spectrum_df.astype(convert_dict)\n",
    "            j+=1\n",
    "\n",
    "interval_upper_bound = 2000//bin_size\n",
    "interval_lower_bound = 0\n",
    "spectrum_range_feature_set = set(range(interval_lower_bound,interval_upper_bound,1)) #this set contains the finalized feature intervals\n",
    "\n",
    "#transform all readings into standard data frame with the same features(spectrum intervals)\n",
    "complemented_spectrum_dict = {}\n",
    "complemented_spectrum_list = []\n",
    "total_spectrum_dict = {}\n",
    "for key_1 in exist_spectrum_dict.keys():\n",
    "    spectrum_dict = exist_spectrum_dict[key_1]\n",
    "    for key_2 in set(spectrum_dict.specid):\n",
    "        spectrum_df = spectrum_dict[spectrum_dict.specid.eq(key_2)]\n",
    "        add_interval_set = spectrum_range_feature_set-set(spectrum_df.interval)\n",
    "        complemented_spectrum_list.append(np.column_stack(([key_2]*len(add_interval_set), list(add_interval_set), [float(0)]*len(add_interval_set))))\n",
    "    complemented_spectrum_np = np.concatenate(complemented_spectrum_list, axis=0)\n",
    "    spectrum_df = pd.DataFrame({'specid':complemented_spectrum_np[:,0], 'interval':complemented_spectrum_np[:,1],'intensity':complemented_spectrum_np[:,2]})            \n",
    "    convert_dict = {'specid': int, 'interval': int} \n",
    "    complemented_spectrum_dict[key_1] = spectrum_df.astype(convert_dict)    \n",
    "\n",
    "    total_spectrum_dict[key_1] = pd.concat([exist_spectrum_dict[key_1], complemented_spectrum_dict[key_1]]).sort_values(by=['specid','interval'])\n",
    "\n",
    "for key_1 in total_spectrum_dict.keys():\n",
    "    spectrum_dict = total_spectrum_dict[key_1]\n",
    "    count_df = spectrum_dict[['specid','interval']].groupby(['specid']).count()\n",
    "    if (len(count_df[count_df.interval != len(spectrum_range_feature_set)]) > 0):\n",
    "        print('there is incorrect data frame in ', key_1)\n",
    "\n",
    "f = open(\"spec_dict.pkl\",\"wb\")\n",
    "pickle.dump(spectrum_dict,f)\n",
    "f.close()\n",
    "\n",
    "mzML_file_names = []\n",
    "for filename in os.listdir(datadir):\n",
    "    if (re.search('\\\\.mzML$', filename)):\n",
    "        mzML_file_names.append(filename)\n",
    "        \n",
    "evidence = pd.read_csv('evidence_csv.csv')\n",
    "evidence = evidence.rename(columns={\"Raw file\": \"mzML_name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest model:\n",
      "parameters of optimal model are: {'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "top 10% important features are:       index         0\n",
      "0   170-180  0.027333\n",
      "1   220-230  0.019837\n",
      "2   410-420  0.016839\n",
      "3   110-120  0.016737\n",
      "4   210-220  0.016654\n",
      "5   280-290  0.016008\n",
      "6   430-440  0.015675\n",
      "7   390-400  0.015581\n",
      "8   640-650  0.015361\n",
      "9   320-330  0.015279\n",
      "10  150-160  0.014733\n",
      "11  660-670  0.014663\n",
      "12  130-140  0.014610\n",
      "13  180-190  0.014535\n",
      "14  400-410  0.014447\n",
      "15  370-380  0.014055\n",
      "16  270-280  0.013947\n",
      "17  120-130  0.013902\n",
      "18  440-450  0.013823\n",
      "19  190-200  0.013803\n",
      "AUC score of optimal model is: 0.8356461948792995\n"
     ]
    }
   ],
   "source": [
    "#combine all mzML file together for training and testing set split\n",
    "totoal_spectrum_df = pd.DataFrame()\n",
    "rename_column = ['spectrum_id']+[str(i*10)+'-'+str(i*10+10) for i in range(200)]+['label']\n",
    "# rename_column = ['spectrum_id']+[str(i*10) for i in range(200)]+['label']\n",
    "for file_name in mzML_file_names:\n",
    "    positive_label = evidence[evidence['mzML_name']==str(file_name.split('.')[0])]\n",
    "    positive_label = positive_label['MS/MS scan number'].to_list()\n",
    "    spec_df = total_spectrum_dict[0]\n",
    "    spec_df_ready = spec_df.pivot(index='specid',columns='interval',values='intensity')\n",
    "    spec_df_ready = spec_df_ready.reset_index()\n",
    "    spec_df_ready['label'] =spec_df_ready['specid'].isin(positive_label)\n",
    "    totoal_spectrum_df = pd.concat([totoal_spectrum_df, spec_df_ready])\n",
    "totoal_spectrum_df.columns = rename_column\n",
    "\n",
    "random.seed(100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(totoal_spectrum_df.iloc[:, 1:201], totoal_spectrum_df.iloc[:,201], test_size=0.2, random_state=42)\n",
    "\n",
    "#define modelling function\n",
    "def modelling_spectrum_quality(X_train, X_test, y_train, y_test):\n",
    "    #random forest modelling:\n",
    "    clf = RandomForestClassifier()\n",
    "    param_grid = { \"min_samples_leaf\" : [2, 5, 10], \"min_samples_split\" : [5, 10, 25], \"n_estimators\": [50, 100, 200]}\n",
    "    gs = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='f1', cv=3, n_jobs=-1) \n",
    "    gs = gs.fit(X_train, y_train)\n",
    "\n",
    "    clf_opt = gs.best_estimator_\n",
    "    clf_opt.fit(X_train,y_train)\n",
    "    feature_scores = pd.Series(clf_opt.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "    feature_scores_df = pd.Series(clf_opt.feature_importances_, index=X_train.columns).sort_values(ascending=False).reset_index()\n",
    "#     print('random forest model:')\n",
    "#     print('parameters of optimal model are:',gs.best_params_)\n",
    "#     print('top 10% important features are:',feature_scores_df.head(round(feature_scores_df.shape[0]*0.1)))\n",
    "#     print('AUC score of optimal model is:',roc_auc_score(y_test, clf_opt.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "    prediction_model = {}\n",
    "    prediction_model['model_params'] = clf_opt.get_params()\n",
    "    prediction_model['AUC'] = roc_auc_score(y_test, clf_opt.predict_proba(X_test)[:, 1])\n",
    "    prediction_model['top_important_features'] = feature_scores_df.head(round(feature_scores_df.shape[0]*0.1))\n",
    "    \n",
    "    #SVM modelling:\n",
    "    svc = SVC(gamma='auto')\n",
    "    param_grid_svc = { \"kernel\" : ['linear', 'rbf']}\n",
    "    gs_svc = GridSearchCV(estimator=svc, param_grid=param_grid_svc, scoring='f1', cv=3, n_jobs=-1) \n",
    "    gs_svc = gs_svc.fit(X_train, y_train)\n",
    "\n",
    "    clf_opt_svc = gs_svc.best_estimator_\n",
    "    clf_opt_svc.fit(X_train,y_train)\n",
    "#     print('support vector machine:')\n",
    "#     print('parameters of optimal model are:',gs_svc.best_params_)\n",
    "#     print('AUC score of optimal model is:',roc_auc_score(y_test, clf_opt_svc.predict_proba(X_test)[:, 1]))\n",
    "    \n",
    "    #select the better model from random forest and SVM by AUC score:\n",
    "    if: roc_auc_score(y_test, clf_opt_svc.predict_proba(X_test)[:, 1])> roc_auc_score(y_test, clf_opt.predict_proba(X_test)[:, 1]):\n",
    "        print('best model for is SVM with AUC:',roc_auc_score(y_test, clf_opt_svc.predict_proba(X_test)[:, 1]))\n",
    "        print('model parameter is:',gs_svc.best_params_)\n",
    "        final_model = clf_opt_svc\n",
    "    else: \n",
    "        print('best model for is random forest with AUC:',roc_auc_score(y_test, clf_opt.predict_proba(X_test)[:, 1]))\n",
    "        print('model parameter is:',gs.best_params_)\n",
    "        final_model = clf_opt\n",
    "    print('selected model is returned')\n",
    "    return(final_model)\n",
    "        \n",
    "modelling_spectrum_quality(X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
